from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OllamaEmbeddings  # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ HuggingFaceBgeEmbeddings Ø¨Ù€ Ollama
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_community.llms import Ollama  # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ HuggingFaceHub Ø¨Ù€ Ollama
import pandas as pd

# âœ… **1ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØªØ§Ø¨ ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙØ©**
pdf_loader = PyPDFLoader("data_analysis_book.pdf")  # Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ø³Ù… ÙƒØªØ§Ø¨Ùƒ
book_documents = pdf_loader.load()

# âœ… **2ï¸âƒ£ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙƒØªØ§Ø¨ Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø·Ø¹ ØµØºÙŠØ±Ø©**
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
split_book_docs = text_splitter.split_documents(book_documents)

# âœ… **3ï¸âƒ£ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø¥Ù„Ù‰ Ù…ØªØ¬Ù‡Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ollama**
embedding_model = OllamaEmbeddings(model="ollama-embedding")  # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù€ Ollama

# âœ… **4ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¬Ù‡ÙŠØ© FAISS**
vector_db = FAISS.from_documents(split_book_docs, embedding_model)

# âœ… **5ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ (Retriever)**
retriever = vector_db.as_retriever(search_type="similarity", search_kwargs={"k": 3})

# âœ… **6ï¸âƒ£ Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ LLM Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ollama**
ollama_model = Ollama(model="mistral")  # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ØªØ§Ø­ Ù„Ø¯ÙŠÙƒ ÙÙŠ Ollama

# âœ… **7ï¸âƒ£ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ù†ØµÙŠ (Prompt)**
analysis_prompt_template = """
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©:
{context}

### Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
{data_sample}

ğŸ“Š **Ø§Ù„ØªØ­Ù„ÙŠÙ„:**
"""

analysis_prompt = PromptTemplate(
    template=analysis_prompt_template,
    input_variables=["context", "data_sample"]
)

# âœ… **8ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Ø³Ù„Ø³Ù„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… RAG**
analysis_chain = RetrievalQA.from_chain_type(
    llm=ollama_model,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True,
    chain_type_kwargs={"prompt": analysis_prompt}
)

# âœ… **9ï¸âƒ£ Ø¯Ø§Ù„Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… RAG ÙˆØ§Ù„ÙƒØªØ§Ø¨**
def analyze_data_with_rag(df):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ù†ØµÙˆØµ
    data_sample = "\n".join([f"{col}: {df[col].astype(str).tolist()[:5]}" for col in df.columns])

    # ØªØ´ØºÙŠÙ„ Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
    result = analysis_chain.invoke({"query": data_sample})

    return result['result']

# âœ… **ğŸ”Ÿ ØªØ¬Ø±Ø¨Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ù CSV**
df = pd.read_csv("Regions.csv")  # Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ø³Ù… Ù…Ù„ÙÙƒ
analysis_result = analyze_data_with_rag(df)

print(analysis_result)
